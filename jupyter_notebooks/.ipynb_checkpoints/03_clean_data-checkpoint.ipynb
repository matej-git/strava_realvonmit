{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "path = 'C:\\\\Users\\\\matej.karkalik\\\\Documents\\\\strava_realvonmit\\\\data\\\\full'\n",
    "files = [f for f in glob.glob(path + \"**/*.csv\", recursive=True)]\n",
    "race_table_all = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_table(race_table, city, race, year):\n",
    "    \n",
    "    if race == 'halfmarathon':\n",
    "        race_length = 21.0975\n",
    "        floor = race_length - 3\n",
    "        cap = race_length + 3\n",
    "        time_cap = 3.5\n",
    "    if race == 'marathon':\n",
    "        race_length = 42.195\n",
    "        floor = race_length - 6\n",
    "        cap = race_length + 6\n",
    "        time_cap = 7\n",
    "    \n",
    "    race_table = race_table.drop(columns = ['Name', 'Strava Activity'])\n",
    "    \n",
    "    # Clear distance\n",
    "    race_table.Distance = race_table.Distance.astype(str).map(lambda x: x.lstrip(\"['\").strip(\"']\"))\n",
    "    race_table.Distance = pd.to_numeric(race_table.Distance, errors='coerce')\n",
    "    # Filter outliers\n",
    "    race_table = race_table[(race_table.Distance<cap) & (race_table.Distance>floor)]\n",
    "    # add info to table\n",
    "    race_table['City'] = city.replace('_',' ').title()\n",
    "    race_table['Year'] = year\n",
    "    race_table['Race_Type'] = race.title()\n",
    "    # Clear wath info\n",
    "    race_table.Watch = race_table.Watch.astype(str).map(lambda x: x.lstrip(\"['\").strip(\"']\"))\n",
    "    race_table.Watch = race_table.Watch.str.replace('<a href=\"/', '')\n",
    "    race_table.Watch = race_table.Watch.str.replace('</a>', '')\n",
    "    race_table.Watch = race_table.Watch.str.replace('mobile\">Strava ', '')\n",
    "    race_table.Watch = race_table.Watch.str.replace('android-wear\">', '')\n",
    "    race_table.Watch = race_table.Watch.str.replace('apple-watch\">', '')\n",
    "    # Jebnute nazvy garminov\n",
    "    race_table.Watch = race_table.Watch.str.replace('vívo', 'vivo')\n",
    "    race_table.Watch = race_table.Watch.str.replace('Vívo', 'vivo')\n",
    "    race_table.Watch = race_table.Watch.str.replace('fēnix', 'fenix')\n",
    "    # Extract watch brand\n",
    "    race_table['Watch_Brand'] = race_table.Watch.str.split().str[0]\n",
    "    # Watch Error\n",
    "    race_table['Watch_Error'] = race_table.Distance - race_length\n",
    "    race_table['Watch_Error_Abs'] = race_table.Watch_Error.abs()\n",
    "    # Clear shoes\n",
    "    race_table.Shoes = race_table.Shoes.map(lambda x: x.lstrip(\"['\").strip(\"']\"))\n",
    "    race_table.Shoes = race_table.Shoes.str.replace('—', 'NA')\n",
    "    race_table.Shoes = [re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", x.strip().lower()) for x in race_table.Shoes]\n",
    "    race_table.Shoes = [x.title() for x in race_table.Shoes]\n",
    "    race_table['Shoes_Brand'] = [x.split(' ', 1)[0] for x in race_table.Shoes]\n",
    "    race_table.Shoes_Brand = race_table.Shoes_Brand.str.replace('New', 'New Balance')\n",
    "    race_table.Shoes_Brand = [x.title() for x in race_table.Shoes_Brand]\n",
    "    race_table.athlet_url = race_table.athlet_url.str.replace('/athletes/', '')\n",
    "    race_table.race_url = race_table.race_url.str.replace('/activities/', '')\n",
    "    race_table['H'] = pd.to_numeric(race_table.Finish.map(lambda x: x.split(\":\")[0]))\n",
    "    race_table['M'] = pd.to_numeric(race_table.Finish.map(lambda x: x.split(\":\")[1]))\n",
    "    race_table['S'] = pd.to_numeric(race_table.Finish.map(lambda x: x.split(\":\")[2]))\n",
    "    race_table['Finish_Numeric'] = race_table.H + race_table.M/60 + race_table.S/3600\n",
    "    race_table = race_table.drop(columns=['H', 'M', 'S'])\n",
    "    # Filter outliers\n",
    "    race_table = race_table[race_table.Finish_Numeric<time_cap]\n",
    "    \n",
    "    race_table = race_table.replace(['na', 'Na', 'nan', '', None], 'NA')\n",
    "    race_table = race_table.rename(columns={'athlet_url': 'Athlet_url', 'race_url': 'Race_url'})\n",
    "    \n",
    "    if 'Pace' in race_table.columns: race_table.drop(columns='Pace')\n",
    "    \n",
    "    race_table.columns = [x.replace('_', ' ') for x in race_table.columns]\n",
    "    \n",
    "    return(race_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    \n",
    "    name_clear = f.rsplit('\\\\', 1)[-1].replace('_full','')\n",
    "    name_list = name_clear.replace('.','_').rsplit('_',3)\n",
    "    \n",
    "    city = name_list[0]\n",
    "    race = name_list[1]\n",
    "    year = name_list[2]\n",
    "        \n",
    "    race_table = pd.read_csv(f, index_col = 0)\n",
    "    race_table = clear_table(race_table, city, race, year)\n",
    "    race_table.to_csv('data/clean/' + name_clear, index=True)\n",
    "    \n",
    "    race_table_all = race_table_all.append(race_table, ignore_index=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_table_all.to_csv('data/clean/race_table_all.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#commet later\n",
    "#race_table = race_table.drop(race_table.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#race_table.Shoes_Brand.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#race_table[race_table.Watch_Brand == 'Suunto'][['Watch', 'Watch_Error_Abs']].groupby(['Watch']).mean().sort_values(by='Watch_Error_Abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(race_table['Watch_Error'], bins = 50)\n",
    "#plt.title('Error Check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(race_table[race_table.Watch_Brand == 'Huami']['Watch_Error'], bins = 10)\n",
    "#plt.title('Amazefit Error Check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(race_table[race_table.Watch_Brand == 'Garmin']['Watch_Error'], bins = 10)\n",
    "#plt.title('Garmin Error Check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#race_table.to_csv(('data/clean/'+city+'_'+race+'_'+year+'.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
